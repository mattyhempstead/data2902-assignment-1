---
title: "DATA2902 Report"
author: "Matty Hempstead 490424010"
subtitle: "Analysis of Class Survey"
date: "23/09/2020"
output: 
  html_document:
      code_folding: hide
      df_print: paged
      fig_caption: yes
      number_sections: yes
      self_contained: yes
      toc: yes
      toc_float: yes
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
```

# Introduction
A class survey was performed among DATA2X02 students through Google Forms, asking a variety of questions from shoe-size to steak preference. In this report, we begin by discussing the effectiveness of the survey in terms of potential biases, and ways in which questions could be improved. We then perform three statistical tests to find potential correlations and relationships that may exist within the data.

```{r, output=F}
# import data

df = read_csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vTf8eDSN_2QbMTyVvO5bdYKZSEEF2bufDdYnLnL-TsR8LM-6x-xu1cxmDMohlbLrkMJn9DE7EG7pg5P/pub?gid=1724783278&single=true&output=csv", col_types=cols())

# Rename all columns
colnames(df) = c("timestamp", "covid_tests", "gender", "postcode", "dentist", "university_hours", "social_media", "dog_or_cat", "live_with_parents", "exercise_hours", "eye_colour", "asthma", "employment_hours", "favourite_season", "shoe_size", "height", "floss", "glasses_or_contacts", "dominant_hand", "steak_preference", "stress_rating")
```


## Potential Biases

```{r, results="hide"}
dim(df)[1]
```

[//]: **What are the potential biases? Which variables are most likely to be subjected to this bias?**

While the survey was offered to all $572$ students, only $174$ responses were recorded. Therefore, the data should *not* be interpreted as reflecting a *random sample of DATA2X02 students*, rather the samples consist only of students who were aware of, and willing to complete the survey. This itself is a potential form of selection bias, as individuals who responded may be the type of students who are more willing to participate and engage in university activities. As a result, this could skew variables such as the number of study hours or stress ratings, as these students may be more likely to spend extra time on university work, and this may correlate with higher (or lower) stress levels.

A large number of questions that are not easily objectively determined could be susceptible to recall or estimation bias. The three questions related to the number of weekly hours spent doing an activity last semester (university, employment, exercising) are likely quite poor estimations given the specificity of the answer. Other questions which may be similarly biased include COVID tests, height (for those students guessing), stress level, last dentist appointment, and flossing frequency.

```{r}
hour_responses = c(unlist(df[,"university_hours"]), unlist(df[,"employment_hours"]), unlist(df[,"exercise_hours"]))
hour_responses = hour_responses[hour_responses > 0]
round_responses = hour_responses[hour_responses %% 5 != 0]
round_responses_percent = 100*length(round_responses)/length(hour_responses)
```
The questions asking for a number of hours are likely susceptible to *round number bias*, where people are more likely to respond with *nice* numbers, like those that end in $5$'s or $0$'s. In the given survey, out of the `r length(hour_responses)` responses to hour-based questions that were greater than $0$, ~$`r round(round_responses_percent)`$% ended with a $5$ or $0$, clearly demonstrating this bias (we expect something closer to $20$%).

In some questions people may deliberately give false data due to social stigmas. For example, respondents may have personal incentive to lie about their height (taller or shorter), frequency of teeth flossing, or the number of study hours, as society generally perceives these as positive attributes.

There is also some subjectiveness in the questions, such as those relating to ranking "stress" and what counts as "exercise" or "university hours". The correct measurements used for shoe size are also not specified, leading to near unusable data.

There is also potentially some bias generated from missing answers, outliers and non-serious responses.

## Potential Improvements

The subjectiveness in certain questions could be removed to obtain more useful data. For example, university work hours could be objectively defined as "hours spent doing work, not including lectures or tutorials". Exercise could also be similarly re-defined, such as "time spent for the purpose of exercise, not including walks". Shoe size could also have a standard measurement defined, as could height.


## Data Processing

Data cleaning was performed by adapting the code of Tarr (2020), addressing some of the issues described in 1.2. Though most variables could do with cleaning, only the data which is analysed underwent pre-processing, as they could affect statistical conclusions.

```{r, warning=F}
# Drop rows with missing values for all entries except timestamp
df = df[apply(!is.na(df[,2:21]), 1, any),]

# Remove two likely non-serious rows
df = df[is.na(df["eye_colour"]) | !(df["eye_colour"] == "orange" | df["eye_colour"] == "Yellow"),]

df = df %>% 
  dplyr::mutate(
    # Standardize gender into male,female,non-binary
    gender = toupper(gender),
    gender = dplyr::case_when(
      startsWith(gender, "M") ~ "male",
      startsWith(gender, "F") ~ "female",
      TRUE ~ "non-binary"
    ),
    
    asthma = dplyr::case_when(
      asthma == "Yes" ~ TRUE,
      TRUE ~ FALSE
    ),
    
    dog_or_cat = dplyr::case_when(
      dog_or_cat == "Yes" ~ TRUE,
      TRUE ~ FALSE
    )
  )

```

The data was provided in CSV form, blank responses were removed along with two other responses that were likely non-serious as indicated by fields such as unlikely eye-colours and preferred social medias. To assist with the categorisation of gender, responses have been simplified down to three categories, "male", "female" and "non-binary". Binary responses for asthma and dog/cat have also been replaced with boolean TRUE/FALSEs.



# Are COVID-19 tests randomly performed?

## Hypothesis
Based on the provided COVID-19 test data, we investigate whether tests are performed at random times with equal likelihood across all students. 
If this was the case, we would expect that the number of tests follows a Poisson distribution, which measures the number of events that occur in a fixed interval of time. The Poisson distribution also assumes that the events occur at the same rate throughout the interval, and are independent from one-another.


```{r, fig.cap="This is some text"}
covid_tests = dplyr::pull(df,"covid_tests")
tests_table = table(factor(covid_tests, levels=0:10))
t(c(c("Responses"), t(tests_table))) %>%
  knitr::kable(col.names=c("Test Count", 0:10))
```
An initial look at the distribution of test counts reveals a set of quickly decreasing values that could plausibly be from a Poisson distribution.


$H_0$: the number of covid cases for each person follows a Poisson distribution.  
$H_1$: the data does not follow a Poisson distribution.

[//]: Out of 174 responses, 172 have a response for the number of times a person has been tested for covid.
[//]: Assume each person is equally likely to receive a test at any given time.
[//]: Since the sum of poissons is also poisson, the probability of a test in a set time period may change over time, as long as it remains constant for all people?
[//]: Each person can be seen as an independant trial.


## Assumptions


We can safely assume the observations are independent, as one student receiving a covid test should not affect the probability of another student receiving a test. Perhaps if the students lived together then tests may be correlated, however this is likely not the case for the vast majority of students.

```{r}
y = unname(table(factor(covid_tests, levels=0:10)))
lambda_est = mean(covid_tests)

# get expected probabilities, ensure they sum to 1
p = dpois(0:10, lambda=lambda_est)
p[11] = 1 - sum(p[0:10])
ey = length(covid_tests) * p

# combine tail to ensure ey >= 5
yr = c(y[1:2], sum(y[3:11]))
pr = c(p[1:2], sum(p[3:11]))
eyr = c(ey[1:2], sum(ey[3:11]))
```
To also ensure the assumption that expected frequencies are $\geq 5$, we group together all observations where the number of tests is at least $2$.

```{r, fig.cap="Figure 2.2: The observed COVID test frequencies vs the expected frequencies assuming a Poisson distribution."}

# plot poisson comparison graph
value = c(yr,eyr)
group = rep(c("0", "1", ">=2"), 2)
type = c(rep("Observed",3), rep("Expected",3))
data.frame(value, group, type) %>%
  ggplot(aes(x=group, y=value, fill=type, x)) + 
  geom_bar(position="dodge", stat="identity") +
  xlab("COVID Tests") + ylab("Response Frequency") 
```

As shown above, the observed frequencies seem to follow the general direction of a Poisson distribution with $\lambda\approx`r round(lambda_est,2)`$, however there does appear to be a noticeable difference for $0$ and $1$ test cases.


## Test
We perform a chi-squared test with 1 degree of freedom. This is because two of the three probabilities are free to vary, and we subtract one since we estimated $\lambda$.

[//]: Talk about why we performed this instead of another test.

Therefore, the test statistic for $\chi_1^2$ is calculated with the following,
$$t_0 = \sum_{i=1}^k \frac{(Y_i-n p_i)^2}{n p_i}$$
where $k=3$, $Y_i$ is the observed value for $i-1$ test cases, and $np_i$ is the expected value for $i-1$ test cases.

```{r}
kr = length(yr)
t0 = sum((yr - eyr)^2/eyr)
pval = 1 - pchisq(t0, df = kr - 1 - 1)
```

Our final test statistic is ~$`r signif(t0, 5)`$ with a p-value of ~$`r signif(pval, 3)`$.

## Results
As $p \leq 0.001$, we reject $H_0$ and accept $H_1$ that covid test cases do not follow a Poisson distribution.

This result can likely be explained with various reasons. For one, it is probable that each student is exposed to covid testing at different rates, with individuals in high-risk areas such as inner-sydney being tested far more often than students in low-risk areas. Furthermore, the memoryless property of a Poisson distribution may not apply, as students who are tested once might have been exposed to the virus or be near others who have been, potentially increasing the chances of future tests.

[//]:Maybe a quick plot of the number of postcode?
[//]:Considering the plot in the assumptions, it might support that memoryless is not obeyed.



# Does having a dog or cat increase the risk of asthma?

## Hypothesis
Pet hair, especially that from dogs or cats, is known to be a catalyst of asthma attacks. 
However, does pet hair simply stimulate asthma attacks among those already with the condition, or is there an underlying correlation between people who report having asthma, and people who have owned dogs or cats?


```{r}
sample = drop_na(df, c("dog_or_cat", "asthma"))
tbl = table(t(sample["dog_or_cat"]), t(sample["asthma"]), dnn=c("dog_or_cat", "asthma"))
tbl = tbl[2:1, 2:1] # flip table to get TRUE,TRUE in top left

odds_ratio = (tbl[1]*tbl[4]) / (tbl[2]*tbl[3])
```

$$
\begin{array} {l|cc}
\text{Dog or Cat \ Asthma}& \text{Yes} &  \text{No}\\ \hline
\text{Yes} & `r tbl[1]` & `r tbl[3]`\\  
\text{No}  & `r tbl[2]` & `r tbl[4]`\\
\end{array}
$$

The contingency table of the observed data (shown above) has an odds ratio of ~$`r round(odds_ratio,2)`$.


$H_0$: The odds ratio of having a dog/cat and having asthma is $1$, meaning those who have had a dog/cat are equally as likely to record having asthma as those who have not.  
$H_1$: The odds ratio is greater than $1$, meaning those who have owned dogs/cats are more likely to report having asthma.  


We choose to perform a one-sided Fisher's Exact Test. The one-sidedness is because we are only interested in whether asthma is positively correlated with pet hair. While a one-sided chi-squared test would also be valid, the data is simple enough to easily perform an exact calculation, allowing for a more accurate p-value.


## Assumptions
A Fisher's Exact Test only needs to make the assumption that the samples are iid. This can be assumed given all responses are from the same student population, and that the presence/absence of a dog/cat or asthma should not affect its presence/absence in another student.

## Test
The test statistic for our one-sided Fisher's Exact Test is found by counting the total number of contingency tables with the same marginal totals, and at least as large an odds ratio. 

```{r, results="hide"}
fisher.test(tbl, alternative="greater")
```
The test reveals a $95$% confidence interval for the odds ratio of $[1.05, \infty]$.
We get a p-value of ~$0.041$.


## Results
Our $95$% confidence interval does not contain the value $1$, and so our p-value $<0.05$.  
We therefore accept $H_1$ that the odds ratio is greater than $1$, and reject $H_0$.

This result is evidence for asthma being not just a genetic condition, but also one that is developed through exposure. However, existing research into the relation between pet ownership and asthma is often quite contradictory. Some studies have shown positive correlation (R Shaw et al. (1994)), where as others have shown inverse relationships (B Brunekreef (1992)). The reasons for such contradictory results are likely to the number of confounding factors. For one, individuals with asthma but no pets may under-report, as they could remain unaware of their condition due to a lack of exposure. Alternatively, Noertjojo, K et al (1999) suggests that pet ownership could be associated with higher rates of household dust, leading to more unrelated asthmatic symptoms. Therefore, these results are mostly inconclusive due to the number of confounding variables at play.



# Who studies more, males or females?

## Hypothesis
Data science has a large over-representation of males, but this does not necessarily reflect performance. In this study we investigate whether females, while less represented, are better at studying for longer periods than males.

Note we limit this study to cisgendered people, as there are only 3 non-binary responses which is not enough data to produce any statistically significant results.

```{r, fig.cap="Figure 4.1: A boxplot demonstrating the difference in weekly study hours between males and females."}
# ignore categories with NA for gender or study hours
sample = drop_na(df, c("gender", "university_hours"))
male_hours = sample["university_hours"][sample["gender"] == "male"]
female_hours = sample["university_hours"][sample["gender"] == "female"]

bplot = boxplot(male_hours, female_hours, names=c("Male", "Female"), horizontal = T, xlab="Average weekly university study hours")

#  remove outliers
outliers = unlist(bplot["out"])
male_hours = male_hours[!male_hours %in% outliers]
female_hours = female_hours[!female_hours %in% outliers]

# remove zero values
male_hours = male_hours[male_hours > 0]
female_hours = female_hours[female_hours > 0]
```
The above boxplot reveals outliers at $70$ and $98$ for males, and $84$ for females. While these values may be technically correct, they are extreme enough that we can safely ignore them, as they do not represent a typical sample from the population. We also choose to ignore zero-values, since this most likely suggests the students were not enrolled in university last semester, which is not relevant to the test.


In the observed data, males have a mean study time of $`r round(mean(male_hours),1)`$ hours, this is less than the females who study for $`r round(mean(female_hours),1)`$.

$H_0$: the true mean weekly study hours is the same among men and women.  
$H_1$: the true mean weekly study hours is greater for women than men.

## Assumptions

We make the assumption that all samples (male or female), are independent from one another, as the study hours of one student should not influence the study hours of another. There is the possibility that some students may be friends, and their study hours may be correlated due to group studying, however we assume this effect is negligible.

We also need the assumption that study hours for both males and females follow a normal distribution, this assumption is verified in the below QQ-plots.  

```{r, fig.cap="Figure 4.2: Side by side qq-plot demonstrating the approximate normality of both male and female samples."}
par(mfrow=c(1,2))

qqnorm(male_hours, main="Male Q-Q Plot", col="blue")
qqline(male_hours)

qqnorm(female_hours, main="Female Q-Q Plot", col="hot pink")
qqline(female_hours)
```
## Test
Given the assumption of iid samples from normal distributions, we perform a one-sided Welch Two-Sample t-test. As we can't assume the two populations have equal variance, a standard Two-Sample t-test is not appropriate.

The test statistic can be calculated with,

$$t_0 = \frac{\bar X-\bar Y}{\sqrt{\frac{S_X^2}{n_x}+\frac{S_Y^2}{n_y}}}$$
```{r, results="hide"}
t.test(male_hours, female_hours, alternative="less")
```
giving a final value for $t_0$ of $-3.24$ and a p-value of ~$0.0016$.

## Results
As $p \leq 0.01$, we reject $H_0$ and accept the alternative hypothesis $H_1$ that the mean study hours are greater for females compared to males.

A similar result has been found in several studies, Al-Shawwa et al. (2014) found that in one sample of 359 medical students, 83% of females studied daily compared to 74% of males. Furthermore, Sahni, M (2012) showed that females are generally better that males at skills which are often related to long study sessions including concentration, recording, and drilling.

However even given these promising results, we should still note the many potential biases present in the university hours data, as stated in 1.1. A study which accounts for these biases may no longer agree with the current conclusion.


# Conclusion

In this report, we propose strong evidence that COVID testing is a non-random process and suggest possible explanations for this result. 
We also provide some evidence to suggest a positive relationship between asthma and pet ownership. However this is a research direction that should be given more focus, as the study was limited by multiple confounding factors that have been suggested in 4.4. Lastly, we show with statistical significance that females typically study more than males, a result that agrees with existing research. Overall however, the existence of many potential biases in the data of this study and others should be addressed first before any action is taken based on the conclusions.

# References

Tarr, G (2020). DATA2002 Data Analytics: Learning from Data. University of Sydney, Sydney Australia.  

Sahni, M (2012), Study Habits of College Students: Differences with Respect to Gender and Academic Stream. Vaish Collage of Education.   
http://www.educationindiajournal.org/home_art_avi.php?path=&id=386

Al-Shawwa et al. (2014), Difference in Studying Habits Between Male and Female Medical Students of King Abdulaziz University. King Abdulaziz University.  
https://www.researchgate.net/publication/264895128_DIFFERENCES_IN_STUDYING_HABITS_BETWEEN_MALE_AND_FEMALE_MEDICAL_STUDENTS_OF_KING_ABDULAZIZ_UNIVERSITY

Noertjojo, K et al (1999), Exposure and sensitization to catdander: Asthma and asthma-likesymptoms among adults, Vancouver, British Columbia.  
https://www.jacionline.org/article/S0091-6749(99)70526-9/pdf

R Shaw et al. (1994), Risk factors for asthma symptoms in Kawerau children, N Z Med J.
https://pubmed.ncbi.nlm.nih.gov/7936475/

B Brunekreef (1992), Pets, allergy and respiratory symptoms in children, Int J Epidemiol.
https://pubmed.ncbi.nlm.nih.gov/1428490/


H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.  

Hadley Wickham, Jim Hester and Romain Francois (2018). readr: Read Rectangular Text Data. R package version 1.3.1.
  https://CRAN.R-project.org/package=readr
  
Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686

Hadley Wickham, Romain Fran?ois, Lionel Henry and Kirill M?ller (2020). dplyr: A Grammar of Data Manipulation. R package version
  1.0.2. https://CRAN.R-project.org/package=dplyr

Yihui Xie (2020). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.29.

